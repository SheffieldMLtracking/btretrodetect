import numpy as np
import os
from glob import glob
import pickle
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
#from sklearn.svm import LinearSVC
import datetime    
import json
from btretrodetect.retrodetect import Retrodetect
from btretrodetect.utils import getstats

configpath = os.path.expanduser('~')+'/.btretrodetect/'
os.makedirs(configpath,exist_ok=True)

class TrainRetrodetectModel():
    def __init__(self,pathtodata,groupby='all',stopearly=None, label_source='btviewer'):
        """
        Manages a dictionary of photo_queues; each photo_queue can then be used to train
        the ML classifier separately. This class is just needed when training the models.
        
        The retrodetect algorithm is applied to each, and human labels searched for and associated.
        
        Parameters:
        - pathtodata: path to the data (this can be e.g. a session or set, etc.) This can be a string or
             a list of strings.
        - groupby: the photo_queues generated could be amalgamated into either separate photo_queues by:
           - 'set'
           - 'camera' (so the same camera in different sets),
           - 'all' (all the data from all the cameras into a single photo_queue). [default]
        - stopearly = ?
        - label_source = the source of the 'clicks', defaults to 'btviewer'
        !! At the moment getting the camera or set from the live data is difficult, so we default to 'all'.
        Stores in 'photo_queues' parameter a dictionary of photo_queues, split depending on groupby.    
        """

        if type(pathtodata)==str: pathtodata = [pathtodata]
        print("About to traverse the following paths:")
        print(pathtodata)
        for pathtodataitem in pathtodata:
            if not os.path.exists(pathtodataitem):
                print("Error: path does not exist: %s" % pathtodataitem)
                return
        X = []
        y = []
        for pathtodataitem in pathtodata:
            for root, dirs, files in os.walk(pathtodataitem):
                _,leaf_folder_name = os.path.split(root)
                if leaf_folder_name==label_source:
                    print("Found %s as a '%s' json folder." % (root,label_source))
                    pathtoimages = os.path.dirname(root)
                    print("Processing images in %s" % pathtoimages)
                    new_X, new_y = self.apply_retrodetect_and_associate_label(pathtoimages,stopearly)
                    X.extend(new_X)
                    y.extend(new_y)
                    print("X has length %d." % len(X))
                    #if groupby == 'set':
                    #    queue_name = '/'.join(os.path.normpath(pathtoimages).split(os.sep)[-3:])
                    #if groupby == 'camera':
                    #    queue_name = os.path.normpath(pathtoimages).split(os.sep)[-1]
                    #if groupby == 'all':
                    #    queue_name = 'all'                
                    #if queue_name not in photo_queues: photo_queues[queue_name] = []
                    #photo_queues[queue_name].extend(photo_queue)       
            #self.photo_queues = photo_queues
            
        self.train_and_save_clf(np.array(X), np.array(y))
        
    def build_patch_dataset(self,photoitem,threshold_dim_patches=5):
        """
        Builds the paired input,output numpy arrays (X,y) for training using the data in photo_queue.
        
        Typically this would be called on a photo_queue generated by "self.apply_retrodetect_and_associate_label",
        as the images in photo_queue need to have been entered into Retrodetect.process_image sequentially,
        to add the imgpatches and need to have had the human-annotations added.

        Parameters:
          - photo_queue = a list of photoitems. Some of them should have a 
            "imgpatches" - a list of candidate patches in the image.
            "labeldata" - a list of human-annotated labels of where the tags really are in the image.
          - threshold_dim_patches = only include patches with a maximum value above this threshold, default 5.
        Returns
          - X = a 2d numpy array, each row is one patch, each column is a feature (from the summary stats)
          - y = boolean labels = whether this is a tag
        """
        patches = []
        labels = []
        
        no_labels_found_warning = True
        no_patches_found_warning = True

        if 'labeldata' not in photoitem: return [],[]
        no_labels_found_warning = False
        if 'imgpatches' not in photoitem: return [],[]
        no_patches_found_warning = False
        for patch in photoitem['imgpatches']:       
            labelcoords = np.array([[label['x'], label['y']] for label in photoitem['labeldata']])
            patchcoord = np.array([patch['x'],patch['y']])            
            true_tag = np.min(np.linalg.norm(labelcoords-patchcoord,axis=1))<6              
            labels.append(true_tag)
            patches.append(patch)
        if no_labels_found_warning: print("No annotations found")
        if no_patches_found_warning: print("No patches found")    
        X = []
        y = []
        for patch,label in zip(patches,labels):
            try:
                stats = getstats(patch)
                if stats is None: continue #failed to generate stats
            except: #some of the patches are on the edge of the image, and we can't compute the stats for these
                continue
            if stats[1]<threshold_dim_patches: continue

            X.append(stats)
            y.append(label)

        return X,y
    
    def apply_retrodetect_and_associate_label(self,pathtoimages,stopearly=None):
        """
        This method:
        1) Loads all the image files in this path, adds them to photo_queue,
        2) then applies the Retrodetect algorithm to them sequentially (as if
           it was running on the tracking box).
        3) For each photo, tries to find the btviewer generated labelled location
           of the tag, and if found adds to the photoitem's dictionary as "labeldata".
        4) Returns this list of image objects.
        """
        
        retrod = Retrodetect(skip_saving=True) #we don't want this method saving images

        X = []
        y = []
        for i,fn in enumerate(sorted(glob(pathtoimages+'/*.np'))):
            try:
                photoitem = np.load(fn,allow_pickle=True)
            except:# UnpicklingError:
                print("Failed to unpickle '%s'." % fn)
                continue
            if not photoitem['greyscale']:  #TODO This might break if greyscale not set
                print("Not a greyscale image, skipping %s, and rest of folder." % fn)
                break
            photoitem['filename'] = fn

            if stopearly is not None: 
                if i>=stopearly: break
        
            retrod.process_image(photoitem)

            _,filename = os.path.split(photoitem['filename'])
            jsonfilename = os.path.join(pathtoimages,'btviewer',filename[:-2]+'json')
            import json
            try:
                labeldata = json.load(open(jsonfilename,'rb'))
                if len(labeldata)==0:
                    continue #skip           
                photoitem['labeldata'] = labeldata
            except FileNotFoundError:
                continue #skip
            new_X, new_y = self.build_patch_dataset(photoitem)
            X.extend(new_X)
            y.extend(new_y)
        return X, y

    
    def train_clf(self,X,y):
        """
        Build a classifier using the training data in X, y.
        """
        print("Building classifier using dataset X is %d x %d" % (X.shape[0],X.shape[1]))
        print("X:")

        for st in ['rawmax ','imgmax ','diffmax ','1.5min ','1.5mean','1.5max ','  3min ',' 3mean ','  3max ','  5min ',' 5mean ','  5max','   | y ']:
            print(st,end="")
        print("")
        print("-"*(X.shape[1]*7+10)) 
        ysort = np.argsort(y)
        for xrow,yrow in zip(X[ysort],y[ysort]):
            for x in xrow: print("%7.1f" % x,end="")
            print("   | %d" % yrow)
        print("---------------------------------------------------")
        
        clf = RandomForestClassifier()#n_estimators = 100, class_weight={False:0.9, True:.1})  
        #clf = LogisticRegression()#class_weight={False:0.9, True:.1})
        #clf = MLPClassifier()#class_weight={False:0.9, True:.1})
        #clf = LinearSVC(dual='auto')#,class_weight={False:0.99, True:.01})
        
        clf.fit(X[::2], y[::2])
        res = clf.predict(X[1::2])==y[1::2]
        
        print("Quick validation test %d of %d correct (%0.0f %%)" % (np.sum(res),len(res),100*np.sum(res)/len(res)))
        print(confusion_matrix(y[1::2],clf.predict(X[1::2])))
        
        return clf.fit(X, y)
       
    def train_and_save_clf(self, X, y, key='all'):
        clfsfile = configpath+'clfs.pkl'
        try:
            clfs = pickle.load(open(clfsfile,'rb'))
        except:
            print("No classifiers found, making new file")
            clfs = {}
        oldkeynum = np.random.randint(1000000) #to be nice, I just move the old classifier to another key...
   
        if key in clfs:
            oldkey = key+'__%d' % oldkeynum
            print("Overwriting classifier for %s (old classifier moved to key='%s'" % (key,oldkey))
            clfs[oldkey] = clfs[key]
        print("Saving classifier as: %s" % key)
        clfs[key] = {'X':X,'y':y,'classifier':self.train_clf(X,y)}
        
        print("Saving classifiers to %s" % clfsfile)
        print("List of classifiers currently saved:")
        for key in clfs.keys():
            print(key)
        pickle.dump(clfs,open(clfsfile,'wb'))
        print("Done (saved to %s)" % clfsfile)
